pe noi ne intereseaza mai mult ð—¼ð˜‚ð˜ð—½ð˜‚ð˜ ð˜‚ð—¹ decat schimba weight urile

dropout :   anulam niste date
            asignam niste probabilitati de dropout: 20% de neuroni ii fortez sa aiba valoarea 0 pt fiecare batch
            valorile care nu s fortate 0 se amplifica (* 1/(1-p)) unde p este probabilitatea de dropout (pt 20%-> (*100/80))