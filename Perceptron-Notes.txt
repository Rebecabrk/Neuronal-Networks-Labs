Notite Curs 3 RN

Perceptron is linear classifier because it is defined by a linear equation.

->The â¡â£â¢â¢ğ˜„ğ—²ğ—¶ğ—´ğ—µğ˜ğ˜€â¡ define a normal vector (perpendicular to the surface) that we can consider a unit vector (of length 1)
->The â¡â£â¢â£ğ—¯ğ—¶ğ—®ğ˜€â¡ defines the distance from the origin to the plane.
->The â¡â£â£â¢ğ—±ğ—¼ğ˜ ğ—½ğ—¿ğ—¼ğ—±ğ˜‚ğ—°ğ˜â¡ will be the ğ˜¯ğ˜°ğ˜³ğ˜® of the the weights.

ğ—™ğ—¼ğ—¿ğ˜„ğ—®ğ—¿ğ—± ğ—½ğ—¿ğ—¼ğ—½ğ—®ğ—´ğ—®ğ˜ğ—¶ğ—¼ğ—»
    Is the process where the input data is passed through the perceptron to get the output.
    1. Compute weighted sum of the inputs and the bias. 
                                z = w * x + b 
                                zâ€‹â€Œâ€â€â€iâ€‹ = Wâ€‹â€Œâ€â€iâ€‹ * x + bâ€‹â€Œâ€â€iâ€‹ (for multiclass classification)
    
    2. Apply activation function to transform the computed weighted sums into ğ˜±ğ˜³ğ˜°ğ˜£ğ˜¢ğ˜£ğ˜ªğ˜­ğ˜ªğ˜µğ˜ªğ˜¦ğ˜´!
       The function can be      ->step function
                                ->sigmoid function  
                                ----------------------- 
                                                (for binary classfication)

                                ->softmax function => for multiclass classification
                                             e^(zâ€‹â€Œâ€â€iâ€‹)                                        
                                        yâ€‹â€Œâ€â€iâ€‹ = ------     
                                            \sumâ€‹â€Œâ€â€jâ€‹ (e^(zâ€‹â€Œâ€â€jâ€‹))
                                    â¡â¢â£â£!â¡The predicted class corresponds to the index of the â¡â¢â£â£highestâ¡ probability

    3. Evaluate the error by comparing the perceptron's output with the actual target value. For multiclass classfication cross entropy loss is commonly used.

ğ—šğ—¿ğ—®ğ—±ğ—¶ğ—²ğ—»ğ˜ ğ—±ğ—²ğ˜€ğ—°ğ—²ğ—»ğ˜       
    Is the process of updating the weights and bias to minimize the error